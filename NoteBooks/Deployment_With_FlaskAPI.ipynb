{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deployment_With_FlaskAPI",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqPchL80rqCE",
        "outputId": "c426bfa1-37b8-4cb1-b6ac-5dea0d20008d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "## Load the data to get started\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "import keras\n",
        "import string\n",
        "import pickle\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "text_to_processing = \"صبااااااهعففففففااااح الفلللللل\"\n",
        "#////////////////////////////////////////////////////////////////////////\n",
        "#preprosessing text:\n",
        "\n",
        "#(1) normalize text:\n",
        "\n",
        "COMMA = u'\\u060C'\n",
        "SEMICOLON = u'\\u061B'\n",
        "QUESTION = u'\\u061F'\n",
        "HAMZA = u'\\u0621'\n",
        "ALEF_MADDA = u'\\u0622'\n",
        "ALEF_HAMZA_ABOVE = u'\\u0623'\n",
        "WAW_HAMZA = u'\\u0624'\n",
        "ALEF_HAMZA_BELOW = u'\\u0625'\n",
        "YEH_HAMZA = u'\\u0626'\n",
        "ALEF = u'\\u0627'\n",
        "BEH = u'\\u0628'\n",
        "TEH_MARBUTA = u'\\u0629'\n",
        "TEH = u'\\u062a'\n",
        "THEH = u'\\u062b'\n",
        "JEEM = u'\\u062c'\n",
        "HAH = u'\\u062d'\n",
        "KHAH = u'\\u062e'\n",
        "DAL = u'\\u062f'\n",
        "THAL = u'\\u0630'\n",
        "REH = u'\\u0631'\n",
        "ZAIN = u'\\u0632'\n",
        "SEEN = u'\\u0633'\n",
        "SHEEN = u'\\u0634'\n",
        "SAD = u'\\u0635'\n",
        "DAD = u'\\u0636'\n",
        "TAH = u'\\u0637'\n",
        "ZAH = u'\\u0638'\n",
        "AIN = u'\\u0639'\n",
        "GHAIN = u'\\u063a'\n",
        "TATWEEL = u'\\u0640'\n",
        "FEH = u'\\u0641'\n",
        "QAF = u'\\u0642'\n",
        "KAF = u'\\u0643'\n",
        "LAM = u'\\u0644'\n",
        "MEEM = u'\\u0645'\n",
        "NOON = u'\\u0646'\n",
        "HEH = u'\\u0647'\n",
        "WAW = u'\\u0648'\n",
        "ALEF_MAKSURA = u'\\u0649'\n",
        "YEH = u'\\u064a'\n",
        "MADDA_ABOVE = u'\\u0653'\n",
        "HAMZA_ABOVE = u'\\u0654'\n",
        "HAMZA_BELOW = u'\\u0655'\n",
        "ZERO = u'\\u0660'\n",
        "ONE = u'\\u0661'\n",
        "TWO = u'\\u0662'\n",
        "THREE = u'\\u0663'\n",
        "FOUR = u'\\u0664'\n",
        "FIVE = u'\\u0665'\n",
        "SIX = u'\\u0666'\n",
        "SEVEN = u'\\u0667'\n",
        "EIGHT = u'\\u0668'\n",
        "NINE = u'\\u0669'\n",
        "PERCENT = u'\\u066a'\n",
        "DECIMAL = u'\\u066b'\n",
        "THOUSANDS = u'\\u066c'\n",
        "STAR = u'\\u066d'\n",
        "MINI_ALEF = u'\\u0670'\n",
        "ALEF_WASLA = u'\\u0671'\n",
        "FULL_STOP = u'\\u06d4'\n",
        "BYTE_ORDER_MARK = u'\\ufeff'\n",
        "\n",
        "# Diacritics\n",
        "FATHATAN = u'\\u064b'\n",
        "DAMMATAN = u'\\u064c'\n",
        "KASRATAN = u'\\u064d'\n",
        "FATHA = u'\\u064e'\n",
        "DAMMA = u'\\u064f'\n",
        "KASRA = u'\\u0650'\n",
        "SHADDA = u'\\u0651'\n",
        "SUKUN = u'\\u0652'\n",
        "\n",
        "#Ligatures\n",
        "LAM_ALEF = u'\\ufefb'\n",
        "LAM_ALEF_HAMZA_ABOVE = u'\\ufef7'\n",
        "LAM_ALEF_HAMZA_BELOW = u'\\ufef9'\n",
        "LAM_ALEF_MADDA_ABOVE = u'\\ufef5'\n",
        "SIMPLE_LAM_ALEF = u'\\u0644\\u0627'\n",
        "SIMPLE_LAM_ALEF_HAMZA_ABOVE = u'\\u0644\\u0623'\n",
        "SIMPLE_LAM_ALEF_HAMZA_BELOW = u'\\u0644\\u0625'\n",
        "SIMPLE_LAM_ALEF_MADDA_ABOVE = u'\\u0644\\u0622'\n",
        "\n",
        "\n",
        "HARAKAT_PAT = re.compile(u\"[\"+u\"\".join([FATHATAN, DAMMATAN, KASRATAN,\n",
        "                                        FATHA, DAMMA, KASRA, SUKUN,\n",
        "                                        SHADDA])+u\"]\")\n",
        "HAMZAT_PAT = re.compile(u\"[\"+u\"\".join([WAW_HAMZA, YEH_HAMZA])+u\"]\")\n",
        "ALEFAT_PAT = re.compile(u\"[\"+u\"\".join([ALEF_MADDA, ALEF_HAMZA_ABOVE,\n",
        "                                       ALEF_HAMZA_BELOW, HAMZA_ABOVE,\n",
        "                                       HAMZA_BELOW])+u\"]\")\n",
        "LAMALEFAT_PAT = re.compile(u\"[\"+u\"\".join([LAM_ALEF,\n",
        "                                          LAM_ALEF_HAMZA_ABOVE,\n",
        "                                          LAM_ALEF_HAMZA_BELOW,\n",
        "LAM_ALEF_MADDA_ABOVE])+u\"]\")\n",
        "\n",
        "\n",
        "\"\"\" https://github.com/cltk/cltk/blob/master/cltk/corpus/arabic/alphabet.py \"\"\"\n",
        "WESTERN_ARABIC_NUMERALS = ['0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "#EASTERN_ARABIC_NUMERALS = [u'\\u06F0', u'\\u06F1', u'\\u06F2', u'\\u06F3', u'\\u0664', u'\\u06F5', u'\\u0666', u'\\u06F7', u'\\u06F8', u'\\u06F9']\n",
        "EASTERN_ARABIC_NUMERALS = [u'۰', u'۱', u'۲', u'۳', u'٤', u'۵', u'٦', u'۷', u'۸', u'۹']\n",
        "\n",
        "eastern_to_western_numerals = {}\n",
        "for i in range(len(EASTERN_ARABIC_NUMERALS)):\n",
        "    eastern_to_western_numerals[EASTERN_ARABIC_NUMERALS[i]] = WESTERN_ARABIC_NUMERALS[i]\n",
        "\n",
        "# Punctuation marks\n",
        "COMMA = u'\\u060C'\n",
        "SEMICOLON = u'\\u061B'\n",
        "QUESTION = u'\\u061F'\n",
        "\n",
        "# Other symbols\n",
        "PERCENT = u'\\u066a'\n",
        "DECIMAL = u'\\u066b'\n",
        "THOUSANDS = u'\\u066c'\n",
        "STAR = u'\\u066d'\n",
        "FULL_STOP = u'\\u06d4'\n",
        "MULITIPLICATION_SIGN = u'\\u00D7'\n",
        "DIVISION_SIGN = u'\\u00F7'\n",
        "\n",
        "arabic_punctuations = COMMA + SEMICOLON + QUESTION + PERCENT + DECIMAL + THOUSANDS + STAR + FULL_STOP + MULITIPLICATION_SIGN + DIVISION_SIGN\n",
        "all_punctuations = string.punctuation + arabic_punctuations + '()[]{}'\n",
        "\n",
        "all_punctuations = ''.join(list(set(all_punctuations)))\n",
        "\n",
        "def strip_tashkeel(text):\n",
        "    text = HARAKAT_PAT.sub('', text)\n",
        "    text = re.sub(u\"[\\u064E]\", \"\", text,  flags=re.UNICODE) # fattha\n",
        "    text = re.sub(u\"[\\u0671]\", \"\", text,  flags=re.UNICODE) # waSla\n",
        "    return text \n",
        "\n",
        "def strip_tatweel(text):\n",
        "    return re.sub(u'[%s]' % TATWEEL, '', text)\n",
        "\n",
        "\n",
        "def remove_non_arabic(text):\n",
        "    return ' '.join(re.sub(u\"[^\\u0621-\\u063A\\u0640-\\u0652 ]\", \" \", text,  flags=re.UNICODE).split())\n",
        "\n",
        "\n",
        "def keep_arabic_english_n_symbols(text):\n",
        "    return ' '.join(re.sub(u\"[^\\u0621-\\u063A\\u0640-\\u064aa-zA-Z#@_:/ ]\", \"\", text,  flags=re.UNICODE).split())\n",
        "\n",
        "\n",
        "def normalize_hamza(text):\n",
        "    text = ALEFAT_PAT.sub(ALEF, text)\n",
        "    return HAMZAT_PAT.sub(HAMZA, text)\n",
        "\n",
        "\n",
        "def normalize_spellerrors(text):\n",
        "    text = re.sub(u'[%s]' % TEH_MARBUTA, HEH, text)\n",
        "    return re.sub(u'[%s]' % ALEF_MAKSURA, YEH, text)\n",
        "\n",
        "\n",
        "def normalize_lamalef(text):\n",
        "    return LAMALEFAT_PAT.sub(u'%s%s'%(LAM, ALEF), text)\n",
        "\n",
        "\n",
        "def normalize_arabic_text(text):\n",
        "    text = remove_non_arabic(text)\n",
        "    text = strip_tashkeel(text)\n",
        "    text = strip_tatweel(text)\n",
        "    text = normalize_lamalef(text)\n",
        "    text = normalize_hamza(text)\n",
        "    text = normalize_spellerrors(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_underscore(text):\n",
        "    return ' '.join(text.split('_'))\n",
        "\n",
        "\n",
        "def remove_retweet_tag(text):\n",
        "    return re.compile('\\#').sub('', re.compile('rt @[a-zA-Z0-9_]+:|@[a-zA-Z0-9_]+').sub('', text).strip())\n",
        "\n",
        "\n",
        "def replace_emails(text):\n",
        "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
        "    for email in emails:\n",
        "        text = text.replace(email,'#')\n",
        "        #text = text.replace(email,' hasEmailAddress ')\n",
        "    return text\n",
        "\n",
        "def replace_urls(text):\n",
        "    return re.sub(r\"http\\S+|www.\\S+\", \"#\", text)\n",
        "    #return re.sub(r\"http\\S+|www.\\S+\", \" hasURL \", text)\n",
        "\n",
        "def convert_eastern_to_western_numerals(text):\n",
        "    for num in EASTERN_ARABIC_NUMERALS:\n",
        "        text = text.replace(num, eastern_to_western_numerals[num])\n",
        "    return text\n",
        "\n",
        "def remove_all_punctuations(text):\n",
        "    for punctuation in all_punctuations:\n",
        "        text = text.replace(punctuation, ' ')\n",
        "    return text\n",
        "\n",
        "def remove_emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def replace_phone_numbers(text):\n",
        "    return re.sub(r'\\d{10}', '#', text)\n",
        "    # return re.sub(r'\\d{10}', ' hasPhoneNumber ', text)\n",
        "\n",
        "def remove_extra_spaces(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def normalize_tweet(text):\n",
        "    new_text = text.lower()\n",
        "    #new_text = normalize_hamza(new_text)\n",
        "    new_text = strip_tashkeel(new_text)\n",
        "    new_text = strip_tatweel(new_text)\n",
        "    new_text = normalize_lamalef(new_text)\n",
        "    #new_text = normalize_spellerrors(new_text)\n",
        "    new_text = remove_retweet_tag(new_text)\n",
        "    new_text = replace_emails(new_text)\n",
        "    new_text = remove_underscore(new_text)\n",
        "    new_text = replace_phone_numbers(new_text)\n",
        "    new_text = remove_all_punctuations(new_text)\n",
        "    new_text = replace_urls(new_text)\n",
        "    new_text = convert_eastern_to_western_numerals(new_text)\n",
        "#    new_text = keep_arabic_english_n_symbols(new_text)\n",
        "    new_text = remove_non_arabic(new_text)\n",
        "    new_text = remove_extra_spaces(new_text)\n",
        "    \n",
        "    return new_text\n",
        "\n",
        "#text_to_processing = normalize_tweet(text_to_processing)\n",
        "\n",
        "#(2) remove repeating char:\n",
        "def remove_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "#text_to_processing =  remove_repeating_char(text_to_processing)\n",
        "\n",
        "\n",
        "#(3) Tokenize Word and Sentence:\n",
        "def tok_word(text):\n",
        "    sentences = text\n",
        "    return nltk.word_tokenize(sentences)\n",
        "\n",
        "\n",
        "\n",
        "#(4) Embedding:\n",
        "\n",
        "def embedding(tweet):\n",
        "\n",
        "    with open('/content/tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle) \n",
        "    \n",
        "        X = tokenizer.texts_to_sequences(tweet)\n",
        "        X = pad_sequences(X,maxlen=20)\n",
        "\n",
        "        return X\n",
        "\n",
        "#text_to_processing =  embedding([text_to_processing])\n",
        "\n",
        "\n",
        "\n",
        "#////////////////////////////////////////////////////\n",
        "#loading model:\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/data_for_colab/ltsm1.h5')\n",
        "#////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "def prediction(tweet):\n",
        "    label_encodding = {\n",
        "    0:\"AE\" , \n",
        "    1:\"BH\" ,\n",
        "    2:\"DZ\",\n",
        "    3:\"EG\",\n",
        "    4:\"IQ\",\n",
        "    5:\"JO\",\n",
        "    6:\"KW\",\n",
        "    7:\"LB\",\n",
        "    8:\"LY\",\n",
        "    9:\"MA\",\n",
        "    10:\"OM\",\n",
        "    11:\"PL\",\n",
        "    12:\"QA\",\n",
        "    13:\"SA\",\n",
        "    14:\"SD\",\n",
        "    15:\"SY\",\n",
        "    16:\"TN\",\n",
        "    17:\"YE\"}\n",
        "    tweet = normalize_tweet(tweet)\n",
        "    tweet = remove_repeating_char(tweet)\n",
        "    tweet = tok_word(tweet)\n",
        "    tweet = embedding([tweet])\n",
        "    print(model.predict(tweet))\n",
        "    pred = model.predict(tweet)\n",
        "    classes_x = np.argmax(pred,axis=1)\n",
        "    print(classes_x)\n",
        "    return (label_encodding.get(classes_x[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template,request"
      ],
      "metadata": {
        "id": "yFM4VDtTrsbU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install flask==0.12.2  # Newer versions of flask don't work in Colab\n",
        "                            # See https://github.com/plotly/dash/issues/257\n",
        "!pip install pyngrok==4.1.1\n",
        "!ngrok authtoken 23YeD7AQSNTQCgxMNACWeo0Xiah_2FcSKgMptZVhcuoFM8txk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llaMyIsr6pLY",
        "outputId": "818cafcd-9797-4a22-ce7e-9d95155353c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (0.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.10.8)\n",
            "Requirement already satisfied: flask==0.12.2 in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->flask==0.12.2) (2.0.1)\n",
            "Requirement already satisfied: pyngrok==4.1.1 in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTvarCVrAfW0",
        "outputId": "93f30ae3-f95b-4bc4-ec7a-91819d4df2b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/data_for_colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY0osHNIHf7U",
        "outputId": "9abbe4be-f039-4306-9ee9-fed5064ef505"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data_for_colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "@app.route('/')\n",
        "def hello_world():\n",
        "    return render_template('index.html')\n",
        "    return prediction(\"تمام\")\n",
        "\n",
        "@app.route('/predict', methods = ['GET', 'POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        glon = request.form['tweet']\n",
        "        glon = prediction(glon)\n",
        "        return render_template('index.html', prediction_text=glon)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgkPJPeG4_4d",
        "outputId": "742efa43-64b8-4152-ce90-5bb340041c89"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://f8cc-35-236-198-90.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2022-03-16 17:01:57,842] ERROR in app: Exception on / [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1982, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1614, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1517, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/_compat.py\", line 33, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1612, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1598, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-7-1abe3626514c>\", line 5, in hello_world\n",
            "    return render_template('index.html')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/templating.py\", line 133, in render_template\n",
            "    return _render(ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jinja2/environment.py\", line 930, in get_or_select_template\n",
            "    return self.get_template(template_name_or_list, parent, globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jinja2/environment.py\", line 883, in get_template\n",
            "    return self._load_template(name, self.make_globals(globals))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jinja2/environment.py\", line 857, in _load_template\n",
            "    template = self.loader.load(self, name, globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jinja2/loaders.py\", line 115, in load\n",
            "    source, filename, uptodate = self.get_source(environment, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/templating.py\", line 57, in get_source\n",
            "    return self._get_source_fast(environment, template)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/templating.py\", line 85, in _get_source_fast\n",
            "    raise TemplateNotFound(template)\n",
            "jinja2.exceptions.TemplateNotFound: index.html\n",
            "127.0.0.1 - - [16/Mar/2022 17:01:57] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:01:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:02] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:03] \"\u001b[37mGET /static/css/style.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:03] \"\u001b[37mGET /static/js/popper.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:03] \"\u001b[37mGET /static/js/bootstrap.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:03] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:03] \"\u001b[37mGET /static/js/jquery.validate.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:06] \"\u001b[37mGET /static/images/bg.jpg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Mar/2022 17:02:14] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.05228831 0.05667659 0.05062848 0.07621626 0.03590252 0.06990962\n",
            "  0.06122079 0.05136033 0.1175257  0.02769295 0.0432961  0.11013079\n",
            "  0.04204806 0.05631416 0.03260037 0.04347604 0.03165913 0.04105388]]\n",
            "[8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [16/Mar/2022 17:02:23] \"\u001b[37mGET /static/js/jquery.min.js HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6yRDUJly5_Ak"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bEUhemPwC860"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}